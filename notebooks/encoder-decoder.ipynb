{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba60443",
   "metadata": {
    "papermill": {
     "duration": 0.01005,
     "end_time": "2023-10-26T07:05:57.968137",
     "exception": false,
     "start_time": "2023-10-26T07:05:57.958087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a19e48e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T07:06:35.519360Z",
     "iopub.status.busy": "2023-10-26T07:06:35.519068Z",
     "iopub.status.idle": "2023-10-26T07:06:44.457709Z",
     "shell.execute_reply": "2023-10-26T07:06:44.456617Z"
    },
    "papermill": {
     "duration": 8.954676,
     "end_time": "2023-10-26T07:06:44.461694",
     "exception": false,
     "start_time": "2023-10-26T07:06:35.507018",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-29T15:24:34.215264282Z",
     "start_time": "2023-10-29T15:24:32.196908565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f5374d9dd70>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Union, Optional\n",
    "from ast import literal_eval\n",
    "from pathlib import Path\n",
    "\n",
    "from torchtext.vocab import Vocab\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from tqdm import tqdm\n",
    "from datasets import load_metric\n",
    "\n",
    "torch.manual_seed(432)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e69677",
   "metadata": {
    "papermill": {
     "duration": 0.011733,
     "end_time": "2023-10-26T07:06:44.485319",
     "exception": false,
     "start_time": "2023-10-26T07:06:44.473586",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "234fedee",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:06:44.511323Z",
     "iopub.status.busy": "2023-10-26T07:06:44.510797Z",
     "iopub.status.idle": "2023-10-26T07:07:27.291478Z",
     "shell.execute_reply": "2023-10-26T07:07:27.290372Z"
    },
    "papermill": {
     "duration": 42.807213,
     "end_time": "2023-10-26T07:07:27.305278",
     "exception": false,
     "start_time": "2023-10-26T07:06:44.498065",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:53:58.258854888Z",
     "start_time": "2023-10-26T16:53:30.178208477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                           reference  \\\n0  [if, alkar, is, flooding, her, with, psychic, ...   \n1               [now, you, ', re, getting, nasty, .]   \n2  [well, ,, we, could, spare, your, life, ,, for...   \n3  [ah, !, monkey, ,, you, ', ve, got, to, snap, ...   \n4     [i, ', ve, got, orders, to, put, her, down, .]   \n\n                                         translation  similarity  lenght_diff  \\\n0  [if, alkar, floods, her, with, her, mental, wa...    0.785171     0.010309   \n1              [you, ', re, becoming, disgusting, .]    0.749687     0.071429   \n2           [well, ,, we, can, spare, your, life, .]    0.919051     0.268293   \n3            [monkey, ,, you, have, to, wake, up, .]    0.664333     0.309524   \n4                [i, have, orders, to, kill, her, .]    0.726639     0.181818   \n\n    ref_tox   trn_tox  \n0  0.014195  0.981983  \n1  0.065473  0.999039  \n2  0.213313  0.985068  \n3  0.053362  0.994215  \n4  0.009402  0.999348  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reference</th>\n      <th>translation</th>\n      <th>similarity</th>\n      <th>lenght_diff</th>\n      <th>ref_tox</th>\n      <th>trn_tox</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[if, alkar, is, flooding, her, with, psychic, ...</td>\n      <td>[if, alkar, floods, her, with, her, mental, wa...</td>\n      <td>0.785171</td>\n      <td>0.010309</td>\n      <td>0.014195</td>\n      <td>0.981983</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[now, you, ', re, getting, nasty, .]</td>\n      <td>[you, ', re, becoming, disgusting, .]</td>\n      <td>0.749687</td>\n      <td>0.071429</td>\n      <td>0.065473</td>\n      <td>0.999039</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[well, ,, we, could, spare, your, life, ,, for...</td>\n      <td>[well, ,, we, can, spare, your, life, .]</td>\n      <td>0.919051</td>\n      <td>0.268293</td>\n      <td>0.213313</td>\n      <td>0.985068</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[ah, !, monkey, ,, you, ', ve, got, to, snap, ...</td>\n      <td>[monkey, ,, you, have, to, wake, up, .]</td>\n      <td>0.664333</td>\n      <td>0.309524</td>\n      <td>0.053362</td>\n      <td>0.994215</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[i, ', ve, got, orders, to, put, her, down, .]</td>\n      <td>[i, have, orders, to, kill, her, .]</td>\n      <td>0.726639</td>\n      <td>0.181818</td>\n      <td>0.009402</td>\n      <td>0.999348</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = Path('..').resolve()\n",
    "data_path = base_path / Path('data/interim/intermediate.tsv')\n",
    "model_cktp_path = base_path / 'models' / 'encoder-decoder.pt'\n",
    "\n",
    "tox_data = pd.read_csv(data_path, sep='\\t', converters={'reference': literal_eval, 'translation': literal_eval})\n",
    "tox_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58263860",
   "metadata": {
    "papermill": {
     "duration": 0.01198,
     "end_time": "2023-10-26T07:07:27.329201",
     "exception": false,
     "start_time": "2023-10-26T07:07:27.317221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "646ae9d8",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:07:27.354107Z",
     "iopub.status.busy": "2023-10-26T07:07:27.353454Z",
     "iopub.status.idle": "2023-10-26T07:07:27.366847Z",
     "shell.execute_reply": "2023-10-26T07:07:27.365954Z"
    },
    "papermill": {
     "duration": 0.028148,
     "end_time": "2023-10-26T07:07:27.368796",
     "exception": false,
     "start_time": "2023-10-26T07:07:27.340648",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:53:58.274072127Z",
     "start_time": "2023-10-26T16:53:58.265153335Z"
    }
   },
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "SPECIAL_SYMBOLS = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "\n",
    "class DeToxificationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset class for de-toxification data.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The input data in a Pandas DataFrame.\n",
    "        vocab (Optional[Vocab]): Vocabulary for tokenization (default: None).\n",
    "        min_tox (float): Minimum toxicity threshold (default: 0.75).\n",
    "        max_length (int): Maximum allowed sequence length (default: 150).\n",
    "        amount_of_pairs (Optional[int]): Number of pairs to use from the dataframe (default: None, using all).\n",
    "\n",
    "    Attributes:\n",
    "        dataframe (pd.DataFrame): The input data in a Pandas DataFrame.\n",
    "        min_tox (float): Minimum toxicity threshold.\n",
    "        max_length (int): Maximum allowed sequence length.\n",
    "        amount_of_pairs (int): Number of pairs to use.\n",
    "        reference (np.ndarray): Reference text data.\n",
    "        translation (np.ndarray): Translation text data.\n",
    "        vocab (Vocab): Vocabulary for tokenization.\n",
    "\n",
    "    Methods:\n",
    "        __init__(self, dataframe, vocab, min_tox, max_length, amount_of_pairs)\n",
    "        _preprocess(self): Preprocess the data based on toxicity and sequence length.\n",
    "        _create_vocab(self) -> Vocab: Create the vocabulary from the reference and translation text.\n",
    "        _get_reference(self, index) -> list[int]: Get tokenized reference text at the given index.\n",
    "        _get_translation(self, index) -> list[int]: Get tokenized translation text at the given index.\n",
    "        __getitem__(self, index) -> tuple[list, list]: Get reference and translation at the given index.\n",
    "        __len__(self) -> int: Get the length of the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 dataframe: pd.DataFrame, \n",
    "                 vocab: Optional[Vocab] = None, \n",
    "                 min_tox: float = 0.75, \n",
    "                 max_length: int = 150,\n",
    "                 amount_of_pairs: Optional[int] = None):\n",
    "        self.dataframe = dataframe\n",
    "        self.min_tox = min_tox\n",
    "        self.max_length = max_length\n",
    "        self.amount_of_pairs: int = amount_of_pairs or len(dataframe)\n",
    "        self._preprocess()\n",
    "        self.reference = self.dataframe['reference'].values[:self.amount_of_pairs]\n",
    "        self.translation = self.dataframe['translation'].values[:self.amount_of_pairs]\n",
    "        self.vocab: Vocab = vocab or self._create_vocab()\n",
    "\n",
    "    def _preprocess(self):\n",
    "        \"\"\"\n",
    "        Preprocess the input data based on toxicity and sequence length.\n",
    "        \"\"\"\n",
    "        self.dataframe = self.dataframe[\n",
    "            (self.dataframe['ref_tox'] >= self.min_tox) &\n",
    "            (self.dataframe['trn_tox'] <= 1 - self.min_tox) &\n",
    "            (self.dataframe['reference'].str.len() <= self.max_length) &\n",
    "            (self.dataframe['translation'].str.len() <= self.max_length)\n",
    "        ]\n",
    "\n",
    "    def _create_vocab(self) -> Vocab:\n",
    "        \"\"\"\n",
    "        Create a vocabulary from the reference and translation text.\n",
    "\n",
    "        Returns:\n",
    "            Vocab: A vocabulary for tokenization.\n",
    "        \"\"\"\n",
    "        new_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "            iter(self.reference + self.translation),\n",
    "            specials=SPECIAL_SYMBOLS\n",
    "        )\n",
    "        new_vocab.set_default_index(UNK_IDX)\n",
    "        return new_vocab\n",
    "\n",
    "    def _get_reference(self, index: int) -> list[int]:\n",
    "        \"\"\"\n",
    "        Get tokenized reference text at the given index.\n",
    "\n",
    "        Args:\n",
    "            index (int): Index of the reference text.\n",
    "\n",
    "        Returns:\n",
    "            list[int]: Tokenized reference text.\n",
    "        \"\"\"\n",
    "        return self.vocab(self.reference[index])\n",
    "\n",
    "    def _get_translation(self, index: int) -> list[int]:\n",
    "        \"\"\"\n",
    "        Get tokenized translation text at the given index.\n",
    "\n",
    "        Args:\n",
    "            index (int): Index of the translation text.\n",
    "\n",
    "        Returns:\n",
    "            list[int]: Tokenized translation text.\n",
    "        \"\"\"\n",
    "        return self.vocab(self.translation[index])\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[list, list]:\n",
    "        return self._get_reference(index), self._get_translation(index)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.amount_of_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d1d2d11",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:07:27.393240Z",
     "iopub.status.busy": "2023-10-26T07:07:27.392952Z",
     "iopub.status.idle": "2023-10-26T07:07:28.796721Z",
     "shell.execute_reply": "2023-10-26T07:07:28.795867Z"
    },
    "papermill": {
     "duration": 1.418588,
     "end_time": "2023-10-26T07:07:28.799206",
     "exception": false,
     "start_time": "2023-10-26T07:07:27.380618",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:53:59.152119084Z",
     "start_time": "2023-10-26T16:53:58.270500757Z"
    }
   },
   "outputs": [],
   "source": [
    "tox_dataset = DeToxificationDataset(tox_data, amount_of_pairs=50000)\n",
    "\n",
    "\n",
    "# splitting dataset into train and validation\n",
    "split_proportion = 0.9\n",
    "size = int(len(tox_dataset) * split_proportion)\n",
    "train_dataset, val_dataset = random_split(tox_dataset, [size, len(tox_dataset) - size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7e94cc4",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:07:28.824169Z",
     "iopub.status.busy": "2023-10-26T07:07:28.823834Z",
     "iopub.status.idle": "2023-10-26T07:07:28.829939Z",
     "shell.execute_reply": "2023-10-26T07:07:28.829101Z"
    },
    "papermill": {
     "duration": 0.020835,
     "end_time": "2023-10-26T07:07:28.831961",
     "exception": false,
     "start_time": "2023-10-26T07:07:28.811126",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:53:59.153944459Z",
     "start_time": "2023-10-26T16:53:59.144795651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pussy . sugar britches .\n",
      "sugar princess !\n"
     ]
    }
   ],
   "source": [
    "def random_sample(some_dataset: DeToxificationDataset, vocab: Vocab):\n",
    "    idx = np.random.randint(0, len(some_dataset))\n",
    "    ref, trn = some_dataset[idx]\n",
    "    print(' '.join(vocab.lookup_tokens(ref)))\n",
    "    print(' '.join(vocab.lookup_tokens(trn)))\n",
    "\n",
    "\n",
    "random_sample(train_dataset, tox_dataset.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10d33e34",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:07:28.855457Z",
     "iopub.status.busy": "2023-10-26T07:07:28.855165Z",
     "iopub.status.idle": "2023-10-26T07:07:28.860800Z",
     "shell.execute_reply": "2023-10-26T07:07:28.859927Z"
    },
    "papermill": {
     "duration": 0.019711,
     "end_time": "2023-10-26T07:07:28.862749",
     "exception": false,
     "start_time": "2023-10-26T07:07:28.843038",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:53:59.161123172Z",
     "start_time": "2023-10-26T16:53:59.153474343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(45000, 5000)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6204a7cf",
   "metadata": {
    "papermill": {
     "duration": 0.011351,
     "end_time": "2023-10-26T07:07:28.885344",
     "exception": false,
     "start_time": "2023-10-26T07:07:28.873993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdf73c4e",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:07:28.909528Z",
     "iopub.status.busy": "2023-10-26T07:07:28.909250Z",
     "iopub.status.idle": "2023-10-26T07:07:28.917179Z",
     "shell.execute_reply": "2023-10-26T07:07:28.916246Z"
    },
    "papermill": {
     "duration": 0.022238,
     "end_time": "2023-10-26T07:07:28.919202",
     "exception": false,
     "start_time": "2023-10-26T07:07:28.896964",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:53:59.211245121Z",
     "start_time": "2023-10-26T16:53:59.161236335Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch: list[np.ndarray]):\n",
    "    ref_list, trn_list, trn_lengths = [], [], []\n",
    "\n",
    "    for _ref, _trn in batch:\n",
    "        ref_list.append(torch.tensor(_ref + [EOS_IDX]))\n",
    "        trn_list.append(torch.tensor(_trn + [EOS_IDX]))\n",
    "        trn_lengths.append(len(_trn))\n",
    "\n",
    "    ref_list = torch.nn.utils.rnn.pad_sequence(ref_list, padding_value=PAD_IDX, batch_first=True)\n",
    "    trn_list = torch.nn.utils.rnn.pad_sequence(trn_list, padding_value=PAD_IDX, batch_first=True)\n",
    "\n",
    "    return ref_list, trn_list, trn_lengths\n",
    "\n",
    "\n",
    "batch_size = 50\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb658ca6",
   "metadata": {
    "papermill": {
     "duration": 0.011286,
     "end_time": "2023-10-26T07:07:28.942509",
     "exception": false,
     "start_time": "2023-10-26T07:07:28.931223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d3be7b8",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:07:28.966535Z",
     "iopub.status.busy": "2023-10-26T07:07:28.966246Z",
     "iopub.status.idle": "2023-10-26T07:07:28.973304Z",
     "shell.execute_reply": "2023-10-26T07:07:28.972441Z"
    },
    "papermill": {
     "duration": 0.021101,
     "end_time": "2023-10-26T07:07:28.975279",
     "exception": false,
     "start_time": "2023-10-26T07:07:28.954178",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:53:59.212043744Z",
     "start_time": "2023-10-26T16:53:59.168029005Z"
    }
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Bahdanau Attention mechanism for sequence-to-sequence models.\n",
    "\n",
    "    Args:\n",
    "        hidden_dim (int): The dimension of the hidden state.\n",
    "\n",
    "    Attributes:\n",
    "        Wa (nn.Linear): Linear transformation for the query.\n",
    "        Ua (nn.Linear): Linear transformation for the keys.\n",
    "        Va (nn.Linear): Linear transformation for the attention scores.\n",
    "        act (nn.Softmax): Softmax activation function for calculating attention weights.\n",
    "\n",
    "    Methods:\n",
    "        forward(self, query, keys) -> tuple[torch.Tensor, torch.Tensor]: Forward pass of the attention mechanism.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim: int):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.Ua = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.Va = nn.Linear(hidden_dim, 1)\n",
    "        self.act = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, query: torch.Tensor, keys: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Calculate the attention scores and context vector.\n",
    "\n",
    "        Args:\n",
    "            query (torch.Tensor): The query tensor.\n",
    "            keys (torch.Tensor): The keys tensor.\n",
    "\n",
    "        Returns:\n",
    "            tuple[torch.Tensor, torch.Tensor]: A tuple containing the context vector and attention weights.\n",
    "        \"\"\"\n",
    "        scores: torch.Tensor = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = self.act(scores)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25e04469",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:07:28.999059Z",
     "iopub.status.busy": "2023-10-26T07:07:28.998794Z",
     "iopub.status.idle": "2023-10-26T07:07:29.010559Z",
     "shell.execute_reply": "2023-10-26T07:07:29.009699Z"
    },
    "papermill": {
     "duration": 0.025955,
     "end_time": "2023-10-26T07:07:29.012788",
     "exception": false,
     "start_time": "2023-10-26T07:07:28.986833",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:53:59.230100061Z",
     "start_time": "2023-10-26T16:53:59.176455719Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder RNN for sequence-to-sequence models.\n",
    "\n",
    "    Args:\n",
    "        num_embeddings (int): The number of unique embeddings.\n",
    "        embedding_dim (int): The dimension of the embedding space.\n",
    "        hidden_dim (int): The dimension of the hidden state.\n",
    "        lstm_layers (int): The number of LSTM layers.\n",
    "        dropout_p (float): Dropout probability (default: 0.1).\n",
    "\n",
    "    Attributes:\n",
    "        lstm_layers (int): The number of LSTM layers.\n",
    "        hidden_dim (int): The dimension of the hidden state.\n",
    "        embedding (nn.Embedding): Embedding layer.\n",
    "        rnn (nn.LSTM): LSTM layers.\n",
    "        dropout (nn.Dropout): Dropout layer.\n",
    "        device (Optional[torch.device]): Device to use (automatically determined).\n",
    "\n",
    "    Methods:\n",
    "        _get_initial_shape(self, x) -> tuple[int, ...]: Get the initial shape for LSTM.\n",
    "        forward(self, x, h_0, c_0) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]: Forward pass of the encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_embeddings: int,\n",
    "                 embedding_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 lstm_layers: int,\n",
    "                 dropout_p: float = 0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=embedding_dim, hidden_size=hidden_dim, num_layers=lstm_layers,\n",
    "            batch_first=True, dropout=dropout_p\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.device: Optional[torch.device] = None\n",
    "\n",
    "    def _get_initial_shape(self, x: torch.Tensor) -> tuple[int, ...]:\n",
    "        \"\"\"\n",
    "        Get the initial shape for LSTM based on the input tensor shape.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            tuple[int, ...]: Initial shape for LSTM.\n",
    "        \"\"\"\n",
    "        if self.device is None:\n",
    "            self.device = torch.device(\"cuda\" if x.get_device() > -1 else \"cpu\")\n",
    "        if len(x.shape) == 2:\n",
    "            return self.lstm_layers, self.hidden_dim\n",
    "        return self.lstm_layers, x.shape[0], self.hidden_dim\n",
    "\n",
    "    def forward(self,\n",
    "                x: torch.Tensor,\n",
    "                h_0: Optional[torch.Tensor] = None,\n",
    "                c_0: Optional[torch.Tensor] = None) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass of the encoder.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "            h_0 (Optional[torch.Tensor]): Initial hidden state tensor (default: None).\n",
    "            c_0 (Optional[torch.Tensor]): Initial cell state tensor (default: None).\n",
    "\n",
    "        Returns:\n",
    "            tuple[torch.Tensor, torch.Tensor, torch.Tensor]: Encoder output, final hidden state, and final cell state.\n",
    "        \"\"\"\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        h_and_c_shape = self._get_initial_shape(embedded)\n",
    "        if h_0 is None:\n",
    "            h_0 = torch.zeros(h_and_c_shape).to(self.device)\n",
    "        if c_0 is None:\n",
    "            c_0 = torch.zeros(h_and_c_shape).to(self.device)\n",
    "\n",
    "        output, (h_n, c_n) = self.rnn(embedded, (h_0, c_0))\n",
    "        return output, h_n, c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1835c9ce",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:07:29.038149Z",
     "iopub.status.busy": "2023-10-26T07:07:29.037872Z",
     "iopub.status.idle": "2023-10-26T07:07:29.055298Z",
     "shell.execute_reply": "2023-10-26T07:07:29.054492Z"
    },
    "papermill": {
     "duration": 0.032266,
     "end_time": "2023-10-26T07:07:29.057246",
     "exception": false,
     "start_time": "2023-10-26T07:07:29.024980",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:53:59.230813326Z",
     "start_time": "2023-10-26T16:53:59.221002755Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention Decoder RNN for sequence-to-sequence models.\n",
    "\n",
    "    Args:\n",
    "        num_embeddings (int): The number of unique embeddings.\n",
    "        embedding_dim (int): The dimension of the embedding space.\n",
    "        hidden_dim (int): The dimension of the hidden state.\n",
    "        lstm_layers (int): The number of LSTM layers.\n",
    "        dropout_p (float): Dropout probability (default: 0.1).\n",
    "\n",
    "    Attributes:\n",
    "        embedding (nn.Embedding): Embedding layer.\n",
    "        rnn (nn.LSTM): LSTM layers.\n",
    "        attention_h (BahdanauAttention): Attention mechanism.\n",
    "        out (nn.Linear): Linear layer for output.\n",
    "        dropout (nn.Dropout): Dropout layer.\n",
    "        device (Optional[torch.device]): Device to use (automatically determined).\n",
    "\n",
    "    Methods:\n",
    "        forward(self, x, h_n, c_n, encoder_outputs, target_tensor, max_length) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "            Forward pass of the decoder.\n",
    "        forward_step(self, decoder_input, decoder_h_0, decoder_c_0, encoder_outputs) -> tuple[torch.Tensor, ...]:\n",
    "            Forward step of the decoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_embeddings: int,\n",
    "                 embedding_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 lstm_layers: int,\n",
    "                 dropout_p: float = 0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=2 * embedding_dim, hidden_size=hidden_dim, num_layers=lstm_layers,\n",
    "            batch_first=True, dropout=dropout_p\n",
    "        )\n",
    "        self.attention_h = BahdanauAttention(hidden_dim)\n",
    "        self.out = nn.Linear(hidden_dim, num_embeddings)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.device: Optional[torch.device] = None\n",
    "\n",
    "    def _set_device(self, x: torch.Tensor):\n",
    "        if self.device is None:\n",
    "            self.device = torch.device(\"cuda\" if x.get_device() > -1 else \"cpu\")\n",
    "\n",
    "    def forward(self,\n",
    "                x: torch.Tensor,\n",
    "                h_n: torch.Tensor,\n",
    "                c_n: torch.Tensor,\n",
    "                encoder_outputs: torch.Tensor,\n",
    "                target_tensor: Optional[torch.Tensor] = None,\n",
    "                max_length: Optional[int] = None):\n",
    "        \"\"\"\n",
    "        Forward pass of the decoder.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "            h_n (torch.Tensor): Initial hidden state tensor.\n",
    "            c_n (torch.Tensor): Initial cell state tensor.\n",
    "            encoder_outputs (torch.Tensor): Outputs from the encoder.\n",
    "            target_tensor (Optional[torch.Tensor]): Target tensor for teacher forcing.\n",
    "            max_length (Optional[int]): Maximum sequence length (default: None).\n",
    "\n",
    "        Returns:\n",
    "            tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]: Decoder outputs, final hidden state, final cell state, and attention weights.\n",
    "        \"\"\"\n",
    "        if max_length is None and target_tensor is None:\n",
    "            raise ValueError(\"either max_length or target_tensor should be specified!\")\n",
    "        if target_tensor is not None:\n",
    "            max_length = target_tensor.shape[1]\n",
    "        self._set_device(x)\n",
    "\n",
    "        b_size = x.shape[0]\n",
    "        decoder_input = torch.empty((b_size, 1), dtype=torch.long).fill_(BOS_IDX).to(self.device)\n",
    "        decoder_h_n = h_n\n",
    "        decoder_c_n = c_n\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(max_length):\n",
    "            decoder_output, decoder_h_n, decoder_c_n, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_h_n, decoder_c_n, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)  # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_h_n, decoder_c_n, attentions\n",
    "\n",
    "    def forward_step(self, \n",
    "                     decoder_input: torch.Tensor, \n",
    "                     decoder_h_0: torch.Tensor,\n",
    "                     decoder_c_0: torch.Tensor,\n",
    "                     encoder_outputs: torch.Tensor) -> tuple[torch.Tensor, ...]:\n",
    "        \"\"\"\n",
    "        Forward step of the decoder.\n",
    "\n",
    "        Args:\n",
    "            decoder_input (torch.Tensor): Input tensor for the step.\n",
    "            decoder_h_0 (torch.Tensor): Initial hidden state tensor.\n",
    "            decoder_c_0 (torch.Tensor): Initial cell state tensor.\n",
    "            encoder_outputs (torch.Tensor): Outputs from the encoder.\n",
    "\n",
    "        Returns:\n",
    "            tuple[torch.Tensor, ...]: Decoder output, final hidden state, final cell state, and attention weights.\n",
    "        \"\"\"\n",
    "        embedded = self.dropout(self.embedding(decoder_input))\n",
    "\n",
    "        query = decoder_h_0[-1].unsqueeze(0).permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention_h(query, encoder_outputs)\n",
    "        input_lstm = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, (h_n, c_n) = self.rnn(input_lstm, (decoder_h_0, decoder_c_0))\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, h_n, c_n, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471ff564",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:07:29.080671Z",
     "iopub.status.busy": "2023-10-26T07:07:29.080378Z",
     "iopub.status.idle": "2023-10-26T07:07:29.088290Z",
     "shell.execute_reply": "2023-10-26T07:07:29.087410Z"
    },
    "papermill": {
     "duration": 0.021632,
     "end_time": "2023-10-26T07:07:29.090114",
     "exception": false,
     "start_time": "2023-10-26T07:07:29.068482",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:53:59.231401381Z",
     "start_time": "2023-10-26T16:53:59.221133210Z"
    }
   },
   "outputs": [],
   "source": [
    "class DeToxification(nn.Module):\n",
    "    \"\"\"\n",
    "    DeToxification model for sequence-to-sequence tasks.\n",
    "\n",
    "    Args:\n",
    "        num_embeddings (int): The number of unique embeddings.\n",
    "        embedding_dim (int): The dimension of the embedding space.\n",
    "        hidden_dim (int): The dimension of the hidden state.\n",
    "        lstm_layers (int): The number of LSTM layers.\n",
    "        dropout_p (float): Dropout probability (default: 0.1).\n",
    "\n",
    "    Attributes:\n",
    "        enc (EncoderRNN): Encoder RNN.\n",
    "        dec (AttnDecoderRNN): Attention Decoder RNN.\n",
    "\n",
    "    Methods:\n",
    "        forward(self, x, target, max_length) -> torch.Tensor: Forward pass of the DeToxification model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_embeddings: int,\n",
    "                 embedding_dim: int,\n",
    "                 hidden_dim: int,\n",
    "                 lstm_layers: int,\n",
    "                 dropout_p: float = 0.1):\n",
    "        super(DeToxification, self).__init__()\n",
    "        self.enc = EncoderRNN(\n",
    "            num_embeddings=num_embeddings,\n",
    "            embedding_dim=embedding_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            lstm_layers=lstm_layers,\n",
    "            dropout_p=dropout_p,\n",
    "        )\n",
    "        self.dec = AttnDecoderRNN(\n",
    "            num_embeddings=num_embeddings,\n",
    "            embedding_dim=embedding_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            lstm_layers=lstm_layers,\n",
    "            dropout_p=dropout_p,\n",
    "        )\n",
    "\n",
    "    def forward(self, \n",
    "                x: torch.Tensor, \n",
    "                target: Optional[torch.Tensor] = None, \n",
    "                max_length: Optional[int] = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the DeToxification model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "            target (Optional[torch.Tensor]): Target tensor for teacher forcing.\n",
    "            max_length (Optional[int]): Maximum sequence length (default: None).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Decoder outputs.\n",
    "        \"\"\"\n",
    "        out_e, h_n_e, c_n_e = self.enc(x)\n",
    "        out_d, _, _, _ = self.dec(x, h_n_e, c_n_e, out_e, target, max_length)\n",
    "        return out_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66391e8",
   "metadata": {
    "papermill": {
     "duration": 0.011488,
     "end_time": "2023-10-26T07:07:29.113001",
     "exception": false,
     "start_time": "2023-10-26T07:07:29.101513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b0b883a",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:07:29.137072Z",
     "iopub.status.busy": "2023-10-26T07:07:29.136795Z",
     "iopub.status.idle": "2023-10-26T07:07:29.141476Z",
     "shell.execute_reply": "2023-10-26T07:07:29.140587Z"
    },
    "papermill": {
     "duration": 0.019176,
     "end_time": "2023-10-26T07:07:29.143542",
     "exception": false,
     "start_time": "2023-10-26T07:07:29.124366",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:53:59.231973672Z",
     "start_time": "2023-10-26T16:53:59.221219770Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_device(dev: torch.device, *args: torch.Tensor) -> tuple[torch.Tensor, ...]:\n",
    "    return tuple(t.to(dev) for t in args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa4b1a77",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:07:29.211245Z",
     "iopub.status.busy": "2023-10-26T07:07:29.210937Z",
     "iopub.status.idle": "2023-10-26T07:07:38.584810Z",
     "shell.execute_reply": "2023-10-26T07:07:38.583890Z"
    },
    "papermill": {
     "duration": 9.388324,
     "end_time": "2023-10-26T07:07:38.586923",
     "exception": false,
     "start_time": "2023-10-26T07:07:29.198599",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:54:01.467595072Z",
     "start_time": "2023-10-26T16:54:00.804297405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DeToxification(\n",
    "    num_embeddings=len(tox_dataset.vocab),\n",
    "    embedding_dim=300,\n",
    "    hidden_dim=300,\n",
    "    lstm_layers=5,\n",
    "    dropout_p=0.3,\n",
    ").to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b6d85ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T18:08:26.901895675Z",
     "start_time": "2023-10-24T18:08:20.590658469Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:07:38.612583Z",
     "iopub.status.busy": "2023-10-26T07:07:38.612286Z",
     "iopub.status.idle": "2023-10-26T07:07:39.074057Z",
     "shell.execute_reply": "2023-10-26T07:07:39.073091Z"
    },
    "papermill": {
     "duration": 0.476923,
     "end_time": "2023-10-26T07:07:39.076326",
     "exception": false,
     "start_time": "2023-10-26T07:07:38.599403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2447dc45e2ee49b09396355987f02a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Metric(name: \"sacrebleu\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id='references')}, usage: \"\"\"\n",
       "Produces BLEU scores along with its sufficient statistics\n",
       "from a source against one or more references.\n",
       "\n",
       "Args:\n",
       "    predictions (`list` of `str`): list of translations to score. Each translation should be tokenized into a list of tokens.\n",
       "    references (`list` of `list` of `str`): A list of lists of references. The contents of the first sub-list are the references for the first prediction, the contents of the second sub-list are for the second prediction, etc. Note that there must be the same number of references for each prediction (i.e. all sub-lists must be of the same length).\n",
       "    smooth_method (`str`): The smoothing method to use, defaults to `'exp'`. Possible values are:\n",
       "        - `'none'`: no smoothing\n",
       "        - `'floor'`: increment zero counts\n",
       "        - `'add-k'`: increment num/denom by k for n>1\n",
       "        - `'exp'`: exponential decay\n",
       "    smooth_value (`float`): The smoothing value. Only valid when `smooth_method='floor'` (in which case `smooth_value` defaults to `0.1`) or `smooth_method='add-k'` (in which case `smooth_value` defaults to `1`).\n",
       "    tokenize (`str`): Tokenization method to use for BLEU. If not provided, defaults to `'zh'` for Chinese, `'ja-mecab'` for Japanese and `'13a'` (mteval) otherwise. Possible values are:\n",
       "        - `'none'`: No tokenization.\n",
       "        - `'zh'`: Chinese tokenization.\n",
       "        - `'13a'`: mimics the `mteval-v13a` script from Moses.\n",
       "        - `'intl'`: International tokenization, mimics the `mteval-v14` script from Moses\n",
       "        - `'char'`: Language-agnostic character-level tokenization.\n",
       "        - `'ja-mecab'`: Japanese tokenization. Uses the [MeCab tokenizer](https://pypi.org/project/mecab-python3).\n",
       "    lowercase (`bool`): If `True`, lowercases the input, enabling case-insensitivity. Defaults to `False`.\n",
       "    force (`bool`): If `True`, insists that your tokenized input is actually detokenized. Defaults to `False`.\n",
       "    use_effective_order (`bool`): If `True`, stops including n-gram orders for which precision is 0. This should be `True`, if sentence-level BLEU will be computed. Defaults to `False`.\n",
       "\n",
       "Returns:\n",
       "    'score': BLEU score,\n",
       "    'counts': Counts,\n",
       "    'totals': Totals,\n",
       "    'precisions': Precisions,\n",
       "    'bp': Brevity penalty,\n",
       "    'sys_len': predictions length,\n",
       "    'ref_len': reference length,\n",
       "\n",
       "Examples:\n",
       "\n",
       "    Example 1:\n",
       "        >>> predictions = [\"hello there general kenobi\", \"foo bar foobar\"]\n",
       "        >>> references = [[\"hello there general kenobi\", \"hello there !\"], [\"foo bar foobar\", \"foo bar foobar\"]]\n",
       "        >>> sacrebleu = datasets.load_metric(\"sacrebleu\")\n",
       "        >>> results = sacrebleu.compute(predictions=predictions, references=references)\n",
       "        >>> print(list(results.keys()))\n",
       "        ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
       "        >>> print(round(results[\"score\"], 1))\n",
       "        100.0\n",
       "\n",
       "    Example 2:\n",
       "        >>> predictions = [\"hello there general kenobi\",\n",
       "        ...                 \"on our way to ankh morpork\"]\n",
       "        >>> references = [[\"hello there general kenobi\", \"hello there !\"],\n",
       "        ...                 [\"goodbye ankh morpork\", \"ankh morpork\"]]\n",
       "        >>> sacrebleu = datasets.load_metric(\"sacrebleu\")\n",
       "        >>> results = sacrebleu.compute(predictions=predictions,\n",
       "        ...                             references=references)\n",
       "        >>> print(list(results.keys()))\n",
       "        ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
       "        >>> print(round(results[\"score\"], 1))\n",
       "        39.8\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the BLUE metric\n",
    "sacrebleu = load_metric(\"sacrebleu\")\n",
    "sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "373aac9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T18:08:27.613405991Z",
     "start_time": "2023-10-24T18:08:27.600622378Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:07:39.103195Z",
     "iopub.status.busy": "2023-10-26T07:07:39.102722Z",
     "iopub.status.idle": "2023-10-26T07:07:39.120491Z",
     "shell.execute_reply": "2023-10-26T07:07:39.119681Z"
    },
    "papermill": {
     "duration": 0.033706,
     "end_time": "2023-10-26T07:07:39.122510",
     "exception": false,
     "start_time": "2023-10-26T07:07:39.088804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(tr_model: nn.Module,\n",
    "          epochs: int, \n",
    "          train_ld: DataLoader, \n",
    "          val_ld: DataLoader,\n",
    "          optim: torch.optim.Optimizer,\n",
    "          loss_fn: nn.CrossEntropyLoss,\n",
    "          vocab: Vocab,\n",
    "          metric,\n",
    "          dev: torch.device,\n",
    "          ckpt_path: Union[Path, str]) -> tuple[list[float], list[float], float]:\n",
    "    \"\"\"\n",
    "    Train a sequence-to-sequence model.\n",
    "\n",
    "    Args:\n",
    "        tr_model (nn.Module): The model to train.\n",
    "        epochs (int): Number of training epochs.\n",
    "        train_ld (DataLoader): Training data DataLoader.\n",
    "        val_ld (DataLoader): Validation data DataLoader.\n",
    "        optim (torch.optim.Optimizer): Optimizer for training.\n",
    "        loss_fn (nn.CrossEntropyLoss): Loss function.\n",
    "        vocab (Vocab): Vocabulary for tokenization.\n",
    "        metric: Evaluation metric.\n",
    "        dev (torch.device): Device for training.\n",
    "        ckpt_path (Union[Path, str]): Path to save the best model checkpoint.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[list[float], list[float], float]: Training losses, validation losses, and the best metric score.\n",
    "    \"\"\"\n",
    "    tr_losses = []\n",
    "    vl_losses = []\n",
    "    _best = 0\n",
    "    # loop for every epoch (training + evaluation)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0\n",
    "    \n",
    "        # progress bar\n",
    "        progress_train = tqdm(enumerate(train_ld, 1), desc=\"Loss: \", total=len(train_ld))\n",
    "    \n",
    "        # ----------------- TRAINING  --------------------\n",
    "        # set model to training\n",
    "        tr_model.train()\n",
    "    \n",
    "        for i, data in progress_train:\n",
    "            inputs, targets = to_device(dev, *data[:-1])\n",
    "    \n",
    "            # training step for single batch\n",
    "            optim.zero_grad()\n",
    "    \n",
    "            outputs = tr_model(inputs, targets)\n",
    "            outputs = outputs.permute(0, 2, 1)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "    \n",
    "            # update running training loss\n",
    "            current_loss = loss.item()\n",
    "            total_loss += current_loss\n",
    "    \n",
    "            # optimizer run\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "    \n",
    "            # updating progress bar\n",
    "            progress_train.set_description(\"Loss: {:.4f}\".format(total_loss / i))\n",
    "\n",
    "            # releasing unnecessary memory in GPU\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "        # releasing unnecessary memory in GPU\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "        # ----------------- VALIDATION  -----------------\n",
    "        # progress bar\n",
    "        progress_val = tqdm(enumerate(val_ld, 1), desc=\"Loss: \", total=len(val_ld))\n",
    "        val_loss_total = 0\n",
    "        metric_total = 0\n",
    "    \n",
    "        # set model to evaluating (testing)\n",
    "        tr_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in progress_val:\n",
    "                lengths = data[-1]\n",
    "                inputs, targets = to_device(dev, *data[:-1])\n",
    "    \n",
    "                outputs = tr_model(inputs, max_length=targets.shape[1])\n",
    "                outputs = outputs.permute(0, 2, 1)\n",
    "    \n",
    "                # update running validation loss\n",
    "                val_loss_total += loss_function(outputs, targets).item()\n",
    "                predicted = outputs.argmax(dim=1)\n",
    "\n",
    "                predicted = predicted.detach().cpu().numpy()\n",
    "                targets = targets.detach().cpu().numpy()\n",
    "    \n",
    "                predicted = [' '.join(vocab.lookup_tokens(row[:ln])) for row, ln in zip(predicted, lengths)]\n",
    "                targets = [[' '.join(vocab.lookup_tokens(row[:ln]))] for row, ln in zip(targets, lengths)]\n",
    "                metric_total += metric.compute(predictions=predicted, references=targets)['score']\n",
    "    \n",
    "                progress_val.set_description(\"Loss: {:.4f}, Sacrebleu: {:.4f}\".format(val_loss_total / i, metric_total / i))\n",
    "\n",
    "                # releasing unnecessary memory in GPU\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "        if _best < metric_total / len(val_ld):\n",
    "            torch.save(tr_model.state_dict(), ckpt_path)\n",
    "            _best = metric_total / len(val_ld)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch}/{epochs}, \"\n",
    "            f\"training loss: {total_loss / len(train_ld):.4f}, \"\n",
    "            f\"validation loss: {val_loss_total / len(val_ld):.4f}, \"\n",
    "            f\"sacrebleu: {metric_total / len(val_ld):.4f}\"\n",
    "        )\n",
    "        tr_losses.append(total_loss / len(train_ld))\n",
    "        vl_losses.append(val_loss_total / len(val_ld))\n",
    "\n",
    "    return tr_losses, vl_losses, _best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "219c8cb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-24T18:08:29.241561857Z",
     "start_time": "2023-10-24T18:08:28.727731125Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T07:07:39.148435Z",
     "iopub.status.busy": "2023-10-26T07:07:39.147741Z",
     "iopub.status.idle": "2023-10-26T08:03:46.476617Z",
     "shell.execute_reply": "2023-10-26T08:03:46.475623Z"
    },
    "papermill": {
     "duration": 3367.343632,
     "end_time": "2023-10-26T08:03:46.478561",
     "exception": false,
     "start_time": "2023-10-26T07:07:39.134929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1976: 100%|██████████| 900/900 [05:23<00:00,  2.78it/s]\n",
      "Loss: 2.0313, Sacrebleu: 0.4438: 100%|██████████| 100/100 [00:10<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, training loss: 2.1976, validation loss: 2.0313, sacrebleu: 0.4438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9752: 100%|██████████| 900/900 [05:26<00:00,  2.76it/s]\n",
      "Loss: 1.9667, Sacrebleu: 0.6741: 100%|██████████| 100/100 [00:10<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, training loss: 1.9752, validation loss: 1.9667, sacrebleu: 0.6741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6245: 100%|██████████| 900/900 [05:25<00:00,  2.77it/s]\n",
      "Loss: 2.7209, Sacrebleu: 2.9515: 100%|██████████| 100/100 [00:10<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, training loss: 1.6245, validation loss: 2.7209, sacrebleu: 2.9515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4448: 100%|██████████| 900/900 [05:25<00:00,  2.77it/s]\n",
      "Loss: 2.8196, Sacrebleu: 4.1398: 100%|██████████| 100/100 [00:10<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, training loss: 1.4448, validation loss: 2.8196, sacrebleu: 4.1398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3320: 100%|██████████| 900/900 [05:26<00:00,  2.76it/s]\n",
      "Loss: 2.9078, Sacrebleu: 4.6309: 100%|██████████| 100/100 [00:10<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, training loss: 1.3320, validation loss: 2.9078, sacrebleu: 4.6309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2645: 100%|██████████| 900/900 [05:23<00:00,  2.78it/s]\n",
      "Loss: 3.0431, Sacrebleu: 5.4558: 100%|██████████| 100/100 [00:10<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, training loss: 1.2645, validation loss: 3.0431, sacrebleu: 5.4558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1885: 100%|██████████| 900/900 [05:24<00:00,  2.77it/s]\n",
      "Loss: 3.1335, Sacrebleu: 6.2904: 100%|██████████| 100/100 [00:10<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, training loss: 1.1885, validation loss: 3.1335, sacrebleu: 6.2904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1282: 100%|██████████| 900/900 [05:29<00:00,  2.74it/s]\n",
      "Loss: 3.2403, Sacrebleu: 6.7012: 100%|██████████| 100/100 [00:10<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, training loss: 1.1282, validation loss: 3.2403, sacrebleu: 6.7012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0819: 100%|██████████| 900/900 [05:26<00:00,  2.76it/s]\n",
      "Loss: 3.2296, Sacrebleu: 6.8398: 100%|██████████| 100/100 [00:10<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, training loss: 1.0819, validation loss: 3.2296, sacrebleu: 6.8398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0368: 100%|██████████| 900/900 [05:25<00:00,  2.76it/s]\n",
      "Loss: 3.3665, Sacrebleu: 7.4520: 100%|██████████| 100/100 [00:10<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, training loss: 1.0368, validation loss: 3.3665, sacrebleu: 7.4520\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, best_score = train(\n",
    "    tr_model=model,\n",
    "    epochs=10,\n",
    "    train_ld=train_dataloader,\n",
    "    val_ld=val_dataloader,\n",
    "    optim=optimizer,\n",
    "    loss_fn=loss_function,\n",
    "    vocab=tox_dataset.vocab,\n",
    "    metric=sacrebleu,\n",
    "    dev=device,\n",
    "    ckpt_path=model_cktp_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "930ea964",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T08:03:49.610987Z",
     "iopub.status.busy": "2023-10-26T08:03:49.610598Z",
     "iopub.status.idle": "2023-10-26T08:03:49.946634Z",
     "shell.execute_reply": "2023-10-26T08:03:49.945733Z"
    },
    "papermill": {
     "duration": 1.947228,
     "end_time": "2023-10-26T08:03:49.948652",
     "exception": false,
     "start_time": "2023-10-26T08:03:48.001424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_arr = np.arange(1, len(train_losses) + 1, 1)\n",
    "plt.title('Train history')\n",
    "plt.plot(epochs_arr, train_losses, c='b', label='Train loss')\n",
    "plt.plot(epochs_arr, val_losses, c='r', label='Validation loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross entroppy loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea629169",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-10-26T08:03:53.178895Z",
     "iopub.status.busy": "2023-10-26T08:03:53.177992Z",
     "iopub.status.idle": "2023-10-26T08:03:53.680403Z",
     "shell.execute_reply": "2023-10-26T08:03:53.679462Z"
    },
    "papermill": {
     "duration": 2.078433,
     "end_time": "2023-10-26T08:03:53.682420",
     "exception": false,
     "start_time": "2023-10-26T08:03:51.603987",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:54:11.822791016Z",
     "start_time": "2023-10-26T16:54:11.464425129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DeToxification(\n  (enc): EncoderRNN(\n    (embedding): Embedding(32331, 300)\n    (rnn): LSTM(300, 300, num_layers=5, batch_first=True, dropout=0.3)\n    (dropout): Dropout(p=0.3, inplace=False)\n  )\n  (dec): AttnDecoderRNN(\n    (embedding): Embedding(32331, 300)\n    (rnn): LSTM(600, 300, num_layers=5, batch_first=True, dropout=0.3)\n    (attention_h): BahdanauAttention(\n      (Wa): Linear(in_features=300, out_features=300, bias=True)\n      (Ua): Linear(in_features=300, out_features=300, bias=True)\n      (Va): Linear(in_features=300, out_features=1, bias=True)\n      (act): Softmax(dim=-1)\n    )\n    (out): Linear(in_features=300, out_features=32331, bias=True)\n    (dropout): Dropout(p=0.3, inplace=False)\n  )\n)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeToxification(\n",
    "    num_embeddings=len(tox_dataset.vocab),\n",
    "    embedding_dim=300,\n",
    "    hidden_dim=300,\n",
    "    lstm_layers=5,\n",
    "    dropout_p=0.3,\n",
    ")\n",
    "model.load_state_dict(torch.load(model_cktp_path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80b191b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T08:03:56.743365Z",
     "iopub.status.busy": "2023-10-26T08:03:56.742983Z",
     "iopub.status.idle": "2023-10-26T08:03:56.752429Z",
     "shell.execute_reply": "2023-10-26T08:03:56.751435Z"
    },
    "papermill": {
     "duration": 1.580071,
     "end_time": "2023-10-26T08:03:56.754336",
     "exception": false,
     "start_time": "2023-10-26T08:03:55.174265",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:54:13.995271863Z",
     "start_time": "2023-10-26T16:54:13.990795611Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "\n",
    "def de_toxification(tr_model: nn.Module, text: str, vocab: Vocab, dev: torch.device, max_length: int = 50) -> str:\n",
    "    \"\"\"\n",
    "    De-toxify a given text using a sequence-to-sequence model.\n",
    "\n",
    "    Args:\n",
    "        tr_model (nn.Module): The trained model for de-toxification.\n",
    "        text (str): The input text to de-toxify.\n",
    "        vocab (Vocab): Vocabulary for tokenization.\n",
    "        dev (torch.device): Device for inference.\n",
    "        max_length (int): Maximum length of the output text (default: 50).\n",
    "\n",
    "    Returns:\n",
    "        str: The de-toxified text.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    garbage = [\n",
    "        '^', '&', '*', '%', '@', '#', '$', '_', '+', '-', '=', '>', '<', ':', '~'\n",
    "    ]\n",
    "    for symbol in garbage:\n",
    "        text = text.replace(symbol, '')\n",
    "    text = text.replace('...', '.')\n",
    "    tokens = tokenizer(text)\n",
    "    tokens_idx = torch.tensor(vocab(tokens) + [EOS_IDX]).unsqueeze(0).to(device)\n",
    "    output = tr_model(tokens_idx, max_length=max_length)\n",
    "    output = output.permute(0, 2, 1)\n",
    "\n",
    "    predicted = output.argmax(dim=1)\n",
    "    predicted = predicted.detach()\n",
    "    if dev.type == 'cuda':\n",
    "        predicted = predicted.cpu()\n",
    "    predicted = predicted.numpy()\n",
    "    predicted = predicted[0]\n",
    "\n",
    "    end_idx = predicted.tolist().index(EOS_IDX)\n",
    "    predicted = predicted[:end_idx] if end_idx > -1 else predicted\n",
    "    predicted = ' '.join(vocab.lookup_tokens(predicted))\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ecf522b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-26T08:03:59.916084Z",
     "iopub.status.busy": "2023-10-26T08:03:59.915354Z",
     "iopub.status.idle": "2023-10-26T08:03:59.982330Z",
     "shell.execute_reply": "2023-10-26T08:03:59.981457Z"
    },
    "papermill": {
     "duration": 1.628538,
     "end_time": "2023-10-26T08:03:59.984261",
     "exception": false,
     "start_time": "2023-10-26T08:03:58.355723",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-26T16:57:47.972573760Z",
     "start_time": "2023-10-26T16:57:47.884566634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you ' re a monster !\n"
     ]
    }
   ],
   "source": [
    "de_tox = de_toxification(model, \"You are dirty bastard!\", tox_dataset.vocab, device)\n",
    "print(de_tox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e383c17cf60ec108"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3491.231341,
   "end_time": "2023-10-26T08:04:04.528944",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-26T07:05:53.297603",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0e900d4ed1d041a59b67142df94752ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2447dc45e2ee49b09396355987f02a73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d442e5468ba8439384a4e058d06a994f",
        "IPY_MODEL_7d6c8bc1de91432e80105f049b068214",
        "IPY_MODEL_6efa990311bb4a0d8ee3dfe4cc012592"
       ],
       "layout": "IPY_MODEL_fd55cd6556474f7a8027d39126a45ac6"
      }
     },
     "333dea4736714d529a333f1800354570": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6b65867f68534f42a1c234b9c8c79906": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6efa990311bb4a0d8ee3dfe4cc012592": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dd28ef3d2f5f4554b641468f0dc58fba",
       "placeholder": "​",
       "style": "IPY_MODEL_93c6970c9fed49579b661784d7a55ae7",
       "value": " 7.65k/? [00:00&lt;00:00, 533kB/s]"
      }
     },
     "7d6c8bc1de91432e80105f049b068214": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6b65867f68534f42a1c234b9c8c79906",
       "max": 2848.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0e900d4ed1d041a59b67142df94752ae",
       "value": 2848.0
      }
     },
     "93c6970c9fed49579b661784d7a55ae7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d442e5468ba8439384a4e058d06a994f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e3dbe0f9af06440fb1758782076bf562",
       "placeholder": "​",
       "style": "IPY_MODEL_333dea4736714d529a333f1800354570",
       "value": "Downloading builder script: "
      }
     },
     "dd28ef3d2f5f4554b641468f0dc58fba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3dbe0f9af06440fb1758782076bf562": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fd55cd6556474f7a8027d39126a45ac6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
